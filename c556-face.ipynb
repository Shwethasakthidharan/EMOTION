{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":234911,"sourceType":"datasetVersion","datasetId":99505}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install keras_preprocessing\n!pip install split-folders","metadata":{"id":"i3p4s90vf6jU","outputId":"9d2f0227-bccd-48d3-abe1-94c44cd31d27","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T22:20:46.710524Z","iopub.execute_input":"2025-02-25T22:20:46.710779Z","iopub.status.idle":"2025-02-25T22:20:54.992507Z","shell.execute_reply.started":"2025-02-25T22:20:46.710758Z","shell.execute_reply":"2025-02-25T22:20:54.991655Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Desired accuracy and validation_accuracy > 83%\n\nimport urllib.request\nimport zipfile\nimport tensorflow as tf\nimport os\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import RMSprop\nimport splitfolders","metadata":{"id":"gLTFWf5Vfncw","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T22:20:54.993564Z","iopub.execute_input":"2025-02-25T22:20:54.993776Z","iopub.status.idle":"2025-02-25T22:21:06.983026Z","shell.execute_reply.started":"2025-02-25T22:20:54.993756Z","shell.execute_reply":"2025-02-25T22:21:06.982145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"jonathanoheix/face-expression-recognition-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T22:21:06.984814Z","iopub.execute_input":"2025-02-25T22:21:06.985411Z","iopub.status.idle":"2025-02-25T22:21:07.782584Z","shell.execute_reply.started":"2025-02-25T22:21:06.985386Z","shell.execute_reply":"2025-02-25T22:21:07.781819Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''with zipfile.ZipFile(\"/kaggle/input/face-expression-recognition-dataset.zip\",\"r\") as z:\n      z.extractall(\".\")\n\nsplitfolders.ratio(\"dataset\", output='data/exp_split', seed=1337, ratio=(0.6, 0.4))'''","metadata":{"id":"KskFcRTIql2L","outputId":"ec509da4-7a25-4fb9-cd1b-35c865b53abb","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T22:21:07.783676Z","iopub.execute_input":"2025-02-25T22:21:07.783967Z","iopub.status.idle":"2025-02-25T22:21:07.789359Z","shell.execute_reply.started":"2025-02-25T22:21:07.783943Z","shell.execute_reply":"2025-02-25T22:21:07.788633Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"TRAINING_DIR = '/kaggle/input/face-expression-recognition-dataset/images/train'\nVALIDATION_DIR = '/kaggle/input/face-expression-recognition-dataset/images/validation'\n\ntrain_datagen = ImageDataGenerator(\n        rescale = 1.0/255.0,\n        width_shift_range = 0.1,\n        height_shift_range = 0.1,\n        rotation_range = 20,\n        horizontal_flip = True\n    )\n\nvalidation_datagen = ImageDataGenerator(\n    rescale= 1.0/255\n)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    TRAINING_DIR,\n    target_size=(56,56),\n    color_mode=\"grayscale\",\n    batch_size=64,\n    class_mode='categorical',\n    shuffle=True\n)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    VALIDATION_DIR,\n    target_size=(56,56),\n    color_mode=\"grayscale\",\n    batch_size=64,\n    class_mode='categorical',\n    shuffle=False\n)","metadata":{"id":"__rkbkM2qW06","outputId":"22883cc6-1762-4544-8f1d-0bca42901bc0","trusted":true,"execution":{"iopub.status.busy":"2025-02-25T22:21:07.790194Z","iopub.execute_input":"2025-02-25T22:21:07.790392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam\n\n\n# Initialising the CNN\nmodel = Sequential()\n\n# 1 - Convolution\nmodel.add(Conv2D(64,(3,3), padding='same', input_shape=(56, 56,1)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 2nd Convolution layer\nmodel.add(Conv2D(128,(5,5), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 3rd Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# 4th Convolution layer\nmodel.add(Conv2D(512,(3,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# Flattening\nmodel.add(Flatten())\n\n# Fully connected layer 1st layer\nmodel.add(Dense(256))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\n# Fully connected layer 2nd layer\nmodel.add(Dense(512))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(7, activation='softmax'))\n\nprint(model.summary())\n\nopt = Adam(learning_rate=0.0001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"id":"ooCqHOLJfylm","outputId":"27e571ca-032a-4d5d-fe05-2ff84042151c","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%%time\n\n# number of epochs to train the NN\nepochs = 1000\n\n# checkpoint to save best model\nfrom keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint(\"model_weights.h5.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\ncallbacks_list = [checkpoint]\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.n // train_generator.batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // validation_generator.batch_size,\n    callbacks=callbacks_list\n)","metadata":{"id":"BqxII7iwo5si","outputId":"c91ae38c-ecda-4ed0-d520-e9669d07a265","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"KXJR5Prvpmw1","trusted":true},"outputs":[],"execution_count":null}]}